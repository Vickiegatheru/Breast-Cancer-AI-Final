# -*- coding: utf-8 -*-
"""notebook49bb7b283e

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/#fileId=https%3A//storage.googleapis.com/kaggle-colab-exported-notebooks/erickumenda/notebook49bb7b283e.8b1eb92d-8b14-49a1-bf60-bab3cb6cf356.ipynb%3FX-Goog-Algorithm%3DGOOG4-RSA-SHA256%26X-Goog-Credential%3Dgcp-kaggle-com%2540kaggle-161607.iam.gserviceaccount.com/20251227/auto/storage/goog4_request%26X-Goog-Date%3D20251227T115818Z%26X-Goog-Expires%3D259200%26X-Goog-SignedHeaders%3Dhost%26X-Goog-Signature%3Da7347a281a18ab1889e00112f336d4ca21a456610bd2809966fd919899d888791f34cff7465c53a5b88ef912d2b83151a204f610f36993a6291a8519194c8ff77ca56bf4dd2639e11a7db98e625f22d3e6171929dfce03ba4588fd9f110276105a5682cff32ea8e0c94274a3693cb061f870a16bbcb77e47fd002366eac204599b270f5c4263338dbbf70b2108313896118b9e7ef8b10a41c5e95c1a17f6181700a8d287e2c37f1c728b37fd4f40b963378d3d2026807fd1bbc2a01517aef53f400c2f1c39014c6dd9905439f6593491bc5270b9aa87ca696dd4d6ac20e4f5b2e81d87c6dac3803befdf3dc745a5fe4df95d15861712a80e1a72abc1c5434c8a
"""

# IMPORTANT: RUN THIS CELL IN ORDER TO IMPORT YOUR KAGGLE DATA SOURCES,
# THEN FEEL FREE TO DELETE THIS CELL.
# NOTE: THIS NOTEBOOK ENVIRONMENT DIFFERS FROM KAGGLE'S PYTHON
# ENVIRONMENT SO THERE MAY BE MISSING LIBRARIES USED BY YOUR
# NOTEBOOK.
import kagglehub
nirrmalgaud_mammogram_mastery_path = kagglehub.dataset_download('nirrmalgaud/mammogram-mastery')

print('Data source import complete.')

import numpy as np
import pandas as pd
import os

base_path = "/kaggle/input/mammogram-mastery/Mammogram Mastery A Robust Dataset for Breast Cancer Detection and Medical Education/Breast Cancer Dataset/Augmented Dataset/"
categories = ["Cancer","Non-Cancer"]

image_paths = []
labels = []

for category in categories:
    category_path = os.path.join(base_path, category)
    for image_name in os.listdir(category_path):
        image_path = os.path.join(category_path, image_name)
        image_paths.append(image_path)
        labels.append(category)

df = pd.DataFrame({
    "image_path": image_paths,
    "label": labels
})

df.head()

df.tail()

df.shape

df.columns

df.duplicated().sum()

df.isnull().sum()

df.info()

df['label'].unique()

df['label'].value_counts()

import seaborn as sns
import matplotlib.pyplot as plt

sns.set_style("whitegrid")

fig, ax = plt.subplots(figsize=(8, 6))
sns.countplot(data=df, x="label", palette="viridis", ax=ax)

ax.set_title("Distribution Types", fontsize=14, fontweight='bold')
ax.set_xlabel("Tumor Type", fontsize=12)
ax.set_ylabel("Count", fontsize=12)

for p in ax.patches:
    ax.annotate(f'{int(p.get_height())}',
                (p.get_x() + p.get_width() / 2., p.get_height()),
                ha='center', va='bottom', fontsize=11, color='black',
                xytext=(0, 5), textcoords='offset points')

plt.show()

label_counts = df["label"].value_counts()

fig, ax = plt.subplots(figsize=(8, 6))
colors = sns.color_palette("viridis", len(label_counts))

ax.pie(label_counts, labels=label_counts.index, autopct='%1.1f%%',
       startangle=140, colors=colors, textprops={'fontsize': 12, 'weight': 'bold'},
       wedgeprops={'edgecolor': 'black', 'linewidth': 1})

ax.set_title("Distribution Types - Pie Chart", fontsize=14, fontweight='bold')

plt.show()

import cv2

num_images = 5

plt.figure(figsize=(15, 12))

for i, category in enumerate(categories):
    category_images = df[df['label'] == category]['image_path'].iloc[:num_images]

    for j, img_path in enumerate(category_images):

        img = cv2.imread(img_path)
        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)

        plt.subplot(len(categories), num_images, i * num_images + j + 1)
        plt.imshow(img)
        plt.axis('off')
        plt.title(category)

plt.tight_layout()
plt.show()

from sklearn.utils import resample

max_count = df['label'].value_counts().max()

dfs = []
for category in df['label'].unique():
    class_subset = df[df['label'] == category]
    class_upsampled = resample(class_subset,
                               replace=True,
                               n_samples=max_count,
                               random_state=42)
    dfs.append(class_upsampled)

df_balanced = pd.concat(dfs).sample(frac=1, random_state=42).reset_index(drop=True)

df_balanced

df = df_balanced

df

import os
os.environ["KERAS_BACKEND"] = "jax"
import keras
from keras import layers
from keras import ops
import numpy as np
import pandas as pd
from PIL import Image
from sklearn.model_selection import train_test_split
from sklearn.metrics import precision_score, recall_score, f1_score
import matplotlib.pyplot as plt

class MammogramDataset(keras.utils.Sequence):
    def __init__(self, dataframe, batch_size=32, image_size=224, shuffle=True, **kwargs):
        super().__init__(**kwargs)
        self.dataframe = dataframe
        self.batch_size = batch_size
        self.image_size = image_size
        self.shuffle = shuffle
        self.label_map = {"Non-Cancer": 0, "Cancer": 1}
        self.indexes = np.arange(len(self.dataframe))
        if self.shuffle:
            np.random.shuffle(self.indexes)
        self.transform = keras.Sequential([
            layers.Resizing(image_size, image_size),
            layers.RandomFlip("horizontal"),
            layers.RandomRotation(factor=0.02),
            layers.Normalization(mean=[0.5], variance=[0.25])
        ])

    def __len__(self):
        return int(np.ceil(len(self.dataframe) / self.batch_size))

    def __getitem__(self, idx):
        start_idx = idx * self.batch_size
        end_idx = min((idx + 1) * self.batch_size, len(self.dataframe))
        batch_indexes = self.indexes[start_idx:end_idx]
        images = []
        labels = []
        for i in batch_indexes:
            img_path = self.dataframe.iloc[i]["image_path"]
            label = self.label_map[self.dataframe.iloc[i]["label"]]
            image = Image.open(img_path).convert("L")
            image = image.resize((self.image_size, self.image_size))
            image = np.array(image)
            image = np.expand_dims(image, axis=-1)
            images.append(image)
            labels.append(label)
        images = np.array(images, dtype=np.float32)
        labels = np.array(labels, dtype=np.int32)
        images = self.transform(images)
        return images, labels

    def on_epoch_end(self):
        if self.shuffle:
            np.random.shuffle(self.indexes)

def mlp(x, hidden_units, dropout_rate):
    for units in hidden_units:
        x = layers.Dense(units, activation=keras.activations.gelu)(x)
        x = layers.Dropout(dropout_rate)(x)
    return x

class Patches(layers.Layer):
    def __init__(self, patch_size):
        super().__init__()
        self.patch_size = patch_size

    def call(self, images):
        input_shape = ops.shape(images)
        batch_size = input_shape[0]
        height = input_shape[1]
        width = input_shape[2]
        channels = input_shape[3]
        num_patches_h = height // self.patch_size
        num_patches_w = width // self.patch_size
        patches = keras.ops.image.extract_patches(images, size=self.patch_size)
        patches = ops.reshape(
            patches,
            (
                batch_size,
                num_patches_h * num_patches_w,
                self.patch_size * self.patch_size * channels,
            ),
        )
        return patches

    def get_config(self):
        config = super().get_config()
        config.update({"patch_size": self.patch_size})
        return config

class PatchEncoder(layers.Layer):
    def __init__(self, num_patches, projection_dim):
        super().__init__()
        self.num_patches = num_patches
        self.projection = layers.Dense(units=projection_dim)
        self.position_embedding = layers.Embedding(
            input_dim=num_patches, output_dim=projection_dim
        )

    def call(self, patch):
        positions = ops.expand_dims(
            ops.arange(start=0, stop=self.num_patches, step=1), axis=0
        )
        projected_patches = self.projection(patch)
        encoded = projected_patches + self.position_embedding(positions)
        return encoded

    def get_config(self):
        config = super().get_config()
        config.update({"num_patches": self.num_patches})
        return config

def create_vit_classifier():
    inputs = keras.Input(shape=(224, 224, 1))
    patches = Patches(patch_size=16)(inputs)
    num_patches = (224 // 16) ** 2
    encoded_patches = PatchEncoder(num_patches, projection_dim=64)(patches)
    for _ in range(8):
        x1 = layers.LayerNormalization(epsilon=1e-6)(encoded_patches)
        attention_output = layers.MultiHeadAttention(
            num_heads=4, key_dim=64, dropout=0.1
        )(x1, x1)
        x2 = layers.Add()([attention_output, encoded_patches])
        x3 = layers.LayerNormalization(epsilon=1e-6)(x2)
        x3 = mlp(x3, hidden_units=[128, 64], dropout_rate=0.1)
        encoded_patches = layers.Add()([x3, x2])
    representation = layers.LayerNormalization(epsilon=1e-6)(encoded_patches)
    representation = layers.Flatten()(representation)
    representation = layers.Dropout(0.5)(representation)
    features = mlp(representation, hidden_units=[2048, 1024], dropout_rate=0.5)
    logits = layers.Dense(2)(features)
    model = keras.Model(inputs=inputs, outputs=logits)
    return model

train_df, val_df = train_test_split(df, test_size=0.2, stratify=df["label"], random_state=42)

train_dataset = MammogramDataset(train_df, batch_size=32, image_size=224, shuffle=True)
val_dataset = MammogramDataset(val_df, batch_size=32, image_size=224, shuffle=False)

model = create_vit_classifier()
optimizer = keras.optimizers.AdamW(learning_rate=0.001, weight_decay=0.0001)
model.compile(
    optimizer=optimizer,
    loss=keras.losses.SparseCategoricalCrossentropy(from_logits=True),
    metrics=[
        keras.metrics.SparseCategoricalAccuracy(name="accuracy")
    ]
)

checkpoint_filepath = "/tmp/checkpoint.weights.h5"
checkpoint_callback = keras.callbacks.ModelCheckpoint(
    checkpoint_filepath,
    monitor="val_accuracy",
    save_best_only=True,
    save_weights_only=True
)
early_stopping = keras.callbacks.EarlyStopping(
    monitor="val_accuracy",     # watch validation accuracy
    mode="max",                 # higher is better
    patience=2,                 # stop after 2 epochs with no improvement
    restore_best_weights=True   # roll back to best epoch automatically
)

history = model.fit(
    train_dataset,
    epochs=10,
    validation_data=val_dataset,
    callbacks=[checkpoint_callback, early_stopping]
)

model.load_weights(checkpoint_filepath)
val_images, val_labels = [], []
for images, labels in val_dataset:
    val_images.append(images)
    val_labels.append(labels)
val_images = np.concatenate(val_images, axis=0)
val_labels = np.concatenate(val_labels, axis=0)
predictions = model.predict(val_images)
predicted_labels = np.argmax(predictions, axis=1)
precision = precision_score(val_labels, predicted_labels)
recall = recall_score(val_labels, predicted_labels)
f1 = f1_score(val_labels, predicted_labels)
print(f"Validation Precision: {precision:.4f}, Recall: {recall:.4f}, F1-Score: {f1:.4f}")

model.save("vit_mammogram_model.keras")

plt.figure(figsize=(12, 5))
plt.subplot(1, 2, 1)
plt.plot(history.history["loss"], label="loss")
plt.plot(history.history["val_loss"], label="val_loss")
plt.xlabel("Epochs")
plt.ylabel("Loss")
plt.title("Train and Validation Loss Over Epochs")
plt.legend()
plt.grid()
plt.subplot(1, 2, 2)
plt.plot(history.history["accuracy"], label="accuracy")
plt.plot(history.history["val_accuracy"], label="val_accuracy")
plt.xlabel("Epochs")
plt.ylabel("Accuracy")
plt.title("Train and Validation Accuracy Over Epochs")
plt.legend()
plt.grid()
plt.tight_layout()
plt.savefig("training_metrics.png")
plt.close()

metrics = ["Precision", "Recall", "F1-Score"]
values = [precision, recall, f1]
plt.figure(figsize=(6, 4))
plt.bar(metrics, values, color=["#1f77b4", "#ff7f0e", "#2ca02c"])
plt.ylim(0, 1)
plt.ylabel("Score")
plt.title("Validation Metrics")
for i, v in enumerate(values):
    plt.text(i, v + 0.01, f"{v:.4f}", ha="center")
plt.savefig("validation_metrics.png")
plt.close()